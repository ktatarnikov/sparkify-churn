{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Churn Classification on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1566641608962_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-11-122.eu-west-1.compute.internal:20888/proxy/application_1566641608962_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-8-21.eu-west-1.compute.internal:8042/node/containerlogs/container_1566641608962_0007_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.sql.functions import split, array, concat, desc, min, max, udf, sum, count, avg, col, when, isnull, isnan, expr, regexp_extract\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, CountVectorizer\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Predict Customer Churn\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.pivotMaxValues', u'50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')"
     ]
    }
   ],
   "source": [
    "# event_data = \"s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json\"\n",
    "# event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "event_data = \"s3n://test-ai-hops/sparkify_event_data.json\"\n",
    "raw_dataset = spark.read.json(event_data)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = raw_dataset.persist()\n",
    "raw_dataset.createOrReplaceTempView(\"sparkify_event_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('all rows: ', 26259199)\n",
      "('after cleaning: ', 25480720)"
     ]
    }
   ],
   "source": [
    "df = raw_dataset\n",
    "print(\"all rows: \", df.count())\n",
    "df = df.dropna(subset=[\"userId\", \"sessionId\", \"page\", \"ts\", \"registration\"])\n",
    "df = df.filter(df[\"userId\"]!=\"\")\n",
    "df = df.filter(df[\"page\"]!=\"\")\n",
    "df = df.persist()\n",
    "print(\"after cleaning: \", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')]"
     ]
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Convert datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hour_millis = 60*60*1000\n",
    "day_millis = 24*60*60*1000\n",
    "week_millis = 7*24*60*60*1000\n",
    "\n",
    "to_spark_time = udf(lambda x : datetime.utcfromtimestamp(x/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "to_day = udf(lambda x : int(x/day_millis))\n",
    "to_week = udf(lambda x : int(x/week_millis))\n",
    "\n",
    "df = df.withColumn('timestamp', to_spark_time('ts'))\n",
    "df = df.withColumn('day', to_day('ts'))\n",
    "df = df.withColumn('week', to_week('ts'))\n",
    "df = df.withColumn('registration_day', to_day('registration'))\n",
    "df = df.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042', timestamp=u'2018-10-01 00:00:01', day=u'17805', week=u'2543', registration_day=u'17751')]"
     ]
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Define Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_window = Window.partitionBy(\"userId\").rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "churn_func = udf(lambda v :1 if v =='Cancellation Confirmation' else 0, IntegerType())\n",
    "df = df.withColumn(\"churn\", churn_func(\"page\")) \\\n",
    "       .withColumn(\"churn\", sum(\"churn\").over(user_window))\n",
    "user_churn = df.select(\"userId\", \"churn\").distinct().persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define location and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location = df.select(\"userId\", \"location\").distinct()\n",
    "split_col = split(user_location['location'], ',')\n",
    "user_city = user_location.withColumn('location_city', split_col.getItem(0)).select(\"userId\", \"location_city\").distinct()\n",
    "user_city = user_city.withColumn(\"location_city\", F.regexp_replace('location_city', '[\\.\\s]', '-')).persist()\n",
    "user_state = user_location.withColumn('location_state', split_col.getItem(1)).select(\"userId\", \"location_state\").distinct().persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_states = user_state.join(user_churn, \"userId\", \"outer\").persist()\n",
    "churn_cities = user_city.join(user_churn, \"userId\", \"outer\").persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 User OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = df.select(\"userId\", \"userAgent\").distinct()\n",
    "# Mozilla/5.0 (Windows NT 6.3; WOW64; rv:31.0)\n",
    "user_os = user_agent.withColumn(\"user_os\", regexp_extract(col('userAgent'), r'Mozilla/5.0 \\(([\\w\\s\\.\\/]*);', 1))\n",
    "user_os = user_os.select(\"userId\", \"user_os\")\n",
    "user_os = user_os.withColumn(\"user_os\", F.regexp_replace('user_os', '[\\.\\s]', '-'))\n",
    "user_os = user_os.withColumn('user_os', when(col('user_os') != '', col('user_os')).otherwise(\"Unknown\")).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Page views (min, max, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_drop = ['Cancel', 'Cancellation Confirmation', 'Downgrade', 'Submit Downgrade', 'Submit Upgrade', 'Upgrade']\n",
    "pages = df.select(\"userId\", \"page\", \"day\")\n",
    "pages = pages.filter(~pages['page'].isin(pages_to_drop))\n",
    "\n",
    "page_view_pivot = \\\n",
    "    pages.groupby(\"userId\", \"day\") \\\n",
    "      .pivot(\"page\")\n",
    "\n",
    "page_view_counts = page_view_pivot.count().fillna(0)\n",
    "page_view_count_avg_per_day = page_view_counts.groupby(\"userId\").avg().persist()\n",
    "page_view_count_min_per_day = page_view_counts.groupby(\"userId\").min().persist()\n",
    "page_view_count_max_per_day = page_view_counts.groupby(\"userId\").max().persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_gender = df.select(\"userId\", \"gender\").distinct().persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 User session stats with service per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_per_week = \\\n",
    "    df.select(\"userId\", \"sessionId\", \"week\")\\\n",
    "      .distinct() \\\n",
    "      .groupby(\"userId\", \"week\") \\\n",
    "      .agg({'sessionId':'count'}) \\\n",
    "      .groupby(\"userId\") \\\n",
    "      .agg(F.min('count(sessionId)'), F.max('count(sessionId)'), F.avg('count(sessionId)')).fillna(0).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_length = df.select(\"userId\", \"length\").groupby(\"userId\").agg({\"length\":\"sum\"}).fillna(0).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Time Since Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_since_registration = \\\n",
    "    df.select(\"userId\", \"ts\", \"registration\")\\\n",
    "      .groupby(\"userId\") \\\n",
    "      .agg(((F.max(\"ts\") - F.avg(\"registration\")) / 1000).alias(\"active_time\")) \\\n",
    "      .persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Items in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_in_session = \\\n",
    "    df.select(\"userId\", \"itemInSession\")\\\n",
    "      .groupby(\"userId\") \\\n",
    "      .agg(F.min('itemInSession'), F.max('itemInSession'), F.avg('itemInSession')) \\\n",
    "      .fillna(0).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Making dataset out of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = user_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_os\n",
    "clf_df = clf_df.join(user_os, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pageview counts per day\n",
    "page_view_count_avg_per_day = page_view_count_avg_per_day.select(\"userId\", \"avg(About)\", \"avg(Error)\", \"avg(NextSong)\", \"avg(Roll Advert)\", \"avg(Thumbs Down)\", \"avg(Thumbs Up)\").persist()\n",
    "page_view_count_min_per_day = page_view_count_min_per_day.select(\"userId\", \"min(Add Friend)\", \"min(Add to Playlist)\", \"min(NextSong)\", \"min(Roll Advert)\", \"min(Thumbs Down)\", \"min(Thumbs Up)\").persist()\n",
    "page_view_count_max_per_day = page_view_count_max_per_day.select(\"userId\", \"max(About)\", \"max(Add Friend)\", \"max(Add to Playlist)\", \"max(NextSong)\", \"max(Roll Advert)\", \"max(Thumbs Down)\").persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = clf_df.join(page_view_count_avg_per_day, \"userId\", \"outer\" ).persist()\n",
    "clf_df = clf_df.join(page_view_count_min_per_day, \"userId\", \"outer\" ).persist()\n",
    "clf_df = clf_df.join(page_view_count_max_per_day, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_in_session = items_in_session.select(\"userId\", \"min(itemInSession)\", \"max(itemInSession)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = clf_df.join(items_in_session, \"userId\", \"outer\").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_per_week = sessions_per_week.select(\"userId\", \"min(count(sessionId))\", \"max(count(sessionId))\", \"avg(count(sessionId))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = clf_df.join(sessions_per_week, \"userId\", \"outer\").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_state\n",
    "clf_df = clf_df.join(user_state, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_city\n",
    "clf_df = clf_df.join(user_city, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_length\n",
    "clf_df = clf_df.join(user_length, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = clf_df.join(time_since_registration, \"userId\", \"outer\" ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- churn: long (nullable = true)\n",
      " |-- user_os: string (nullable = true)\n",
      " |-- avg(About): double (nullable = true)\n",
      " |-- avg(Error): double (nullable = true)\n",
      " |-- avg(NextSong): double (nullable = true)\n",
      " |-- avg(Roll Advert): double (nullable = true)\n",
      " |-- avg(Thumbs Down): double (nullable = true)\n",
      " |-- avg(Thumbs Up): double (nullable = true)\n",
      " |-- min(Add Friend): long (nullable = true)\n",
      " |-- min(Add to Playlist): long (nullable = true)\n",
      " |-- min(NextSong): long (nullable = true)\n",
      " |-- min(Roll Advert): long (nullable = true)\n",
      " |-- min(Thumbs Down): long (nullable = true)\n",
      " |-- min(Thumbs Up): long (nullable = true)\n",
      " |-- max(About): long (nullable = true)\n",
      " |-- max(Add Friend): long (nullable = true)\n",
      " |-- max(Add to Playlist): long (nullable = true)\n",
      " |-- max(NextSong): long (nullable = true)\n",
      " |-- max(Roll Advert): long (nullable = true)\n",
      " |-- max(Thumbs Down): long (nullable = true)\n",
      " |-- min(itemInSession): long (nullable = true)\n",
      " |-- max(itemInSession): long (nullable = true)\n",
      " |-- min(count(sessionId)): long (nullable = true)\n",
      " |-- max(count(sessionId)): long (nullable = true)\n",
      " |-- avg(count(sessionId)): double (nullable = true)\n",
      " |-- location_state: string (nullable = true)\n",
      " |-- location_city: string (nullable = true)\n",
      " |-- sum(length): double (nullable = true)\n",
      " |-- active_time: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "clf_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column userId has 0 missing values.\n",
      "Column churn has 0 missing values.\n",
      "Column user_os has 0 missing values.\n",
      "Column avg(About) has 0 missing values.\n",
      "Column avg(Error) has 0 missing values.\n",
      "Column avg(NextSong) has 0 missing values.\n",
      "Column avg(Roll Advert) has 0 missing values.\n",
      "Column avg(Thumbs Down) has 0 missing values.\n",
      "Column avg(Thumbs Up) has 0 missing values.\n",
      "Column min(Add Friend) has 0 missing values.\n",
      "Column min(Add to Playlist) has 0 missing values.\n",
      "Column min(NextSong) has 0 missing values.\n",
      "Column min(Roll Advert) has 0 missing values.\n",
      "Column min(Thumbs Down) has 0 missing values.\n",
      "Column min(Thumbs Up) has 0 missing values.\n",
      "Column max(About) has 0 missing values.\n",
      "Column max(Add Friend) has 0 missing values.\n",
      "Column max(Add to Playlist) has 0 missing values.\n",
      "Column max(NextSong) has 0 missing values.\n",
      "Column max(Roll Advert) has 0 missing values.\n",
      "Column max(Thumbs Down) has 0 missing values.\n",
      "Column min(itemInSession) has 0 missing values.\n",
      "Column max(itemInSession) has 0 missing values.\n",
      "Column min(count(sessionId)) has 0 missing values.\n",
      "Column max(count(sessionId)) has 0 missing values.\n",
      "Column avg(count(sessionId)) has 0 missing values.\n",
      "Column location_state has 0 missing values.\n",
      "Column location_city has 0 missing values.\n",
      "Column sum(length) has 0 missing values.\n",
      "Column active_time has 0 missing values."
     ]
    }
   ],
   "source": [
    "for coln in clf_df.columns:\n",
    "    missing_count = clf_df.filter((isnan(clf_df[coln])) | (clf_df[coln].isNull()) | (clf_df[coln] == \"\")).count()\n",
    "    print(\"Column {} has {} missing values.\".format(coln, missing_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = clf_df.drop(\"userId\").fillna(0).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = [['churn', 'churn'], \n",
    "                   ['user_os', 'user_os'],\n",
    "                   ['location_state', 'location_state'],\n",
    "                   ['location_city', 'location_city'],\n",
    "                   ['sum(length)', 'length_sum'],\n",
    "                   ['avg(About)', 'page_view_about_avg'],\n",
    "                   ['avg(Error)', 'page_view_error_avg'],\n",
    "                   ['avg(NextSong)', 'page_view_next_song_avg'],\n",
    "                   ['avg(Roll Advert)', 'page_view_roll_advert_avg'],\n",
    "                   ['avg(Thumbs Down)', 'page_view_thumbs_down_avg'],\n",
    "                   ['avg(Thumbs Up)', 'page_view_thumbs_up_avg'],\n",
    "                   ['min(Add Friend)', 'page_view_add_friend_min'],\n",
    "                   ['min(Add to Playlist)', 'page_view_add_to_playlist_min'],\n",
    "                   ['min(NextSong)', 'page_view_next_song_min'],\n",
    "                   ['min(Roll Advert)', 'page_view_roll_advert_min'],\n",
    "                   ['min(Thumbs Down)', 'page_view_thumbs_down_min'],\n",
    "                   ['min(Thumbs Up)', 'page_view_thumbs_up_min'],\n",
    "                   ['max(About)', 'page_view_about_max'],\n",
    "                   ['max(Add Friend)', 'page_view_add_friend_max'],\n",
    "                   ['max(Add to Playlist)', 'page_view_add_to_playlist_max'],\n",
    "                   ['max(NextSong)', 'page_view_next_song_max'],\n",
    "                   ['max(Roll Advert)', 'page_view_roll_advert_max'],\n",
    "                   ['max(Thumbs Down)', 'page_view_thumbs_down_max'],\n",
    "                   ['min(itemInSession)', 'item_in_session_min'],\n",
    "                   ['max(itemInSession)', 'item_in_session_max'],\n",
    "                   ['min(count(sessionId))', 'session_count_min'],\n",
    "                   ['avg(count(sessionId))', 'session_count_avg'],\n",
    "                   ['max(count(sessionId))', 'session_count_max']]\n",
    "mapping = {m[0]:m[1] for m in mapping_list}\n",
    "dataset = dataset.select([F.col(c).alias(mapping.get(c, c)) for c in dataset.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.createOrReplaceTempView(\"input_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- churn: long (nullable = true)\n",
      " |-- user_os: string (nullable = true)\n",
      " |-- page_view_about_avg: double (nullable = false)\n",
      " |-- page_view_error_avg: double (nullable = false)\n",
      " |-- page_view_next_song_avg: double (nullable = false)\n",
      " |-- page_view_roll_advert_avg: double (nullable = false)\n",
      " |-- page_view_thumbs_down_avg: double (nullable = false)\n",
      " |-- page_view_thumbs_up_avg: double (nullable = false)\n",
      " |-- page_view_add_friend_min: long (nullable = true)\n",
      " |-- page_view_add_to_playlist_min: long (nullable = true)\n",
      " |-- page_view_next_song_min: long (nullable = true)\n",
      " |-- page_view_roll_advert_min: long (nullable = true)\n",
      " |-- page_view_thumbs_down_min: long (nullable = true)\n",
      " |-- page_view_thumbs_up_min: long (nullable = true)\n",
      " |-- page_view_about_max: long (nullable = true)\n",
      " |-- page_view_add_friend_max: long (nullable = true)\n",
      " |-- page_view_add_to_playlist_max: long (nullable = true)\n",
      " |-- page_view_next_song_max: long (nullable = true)\n",
      " |-- page_view_roll_advert_max: long (nullable = true)\n",
      " |-- page_view_thumbs_down_max: long (nullable = true)\n",
      " |-- item_in_session_min: long (nullable = true)\n",
      " |-- item_in_session_max: long (nullable = true)\n",
      " |-- session_count_min: long (nullable = true)\n",
      " |-- session_count_max: long (nullable = true)\n",
      " |-- session_count_avg: double (nullable = false)\n",
      " |-- location_state: string (nullable = true)\n",
      " |-- location_city: string (nullable = true)\n",
      " |-- length_sum: double (nullable = false)\n",
      " |-- active_time: double (nullable = false)"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.withColumn(\"length_sum\", F.log(dataset[\"length_sum\"] + 1))\n",
    "dataset = dataset.withColumn(\"active_time\", F.log(dataset[\"active_time\"] + 1))\n",
    "dataset = dataset.persist()\n",
    "dataset.createOrReplaceTempView(\"input_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_get_f1score(context, cv_model, data):\n",
    "    results = cv_model.transform(data)\n",
    "    prediction_evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "    print(\"  evaluation on \", context, \"...\")\n",
    "    f1score = prediction_evaluator.evaluate(results, {prediction_evaluator.metricName: \"f1\"})\n",
    "    print(\"  precision\", prediction_evaluator.evaluate(results, {prediction_evaluator.metricName: \"weightedPrecision\"}))\n",
    "    print(\"  recall\", prediction_evaluator.evaluate(results, {prediction_evaluator.metricName: \"weightedRecall\"}))\n",
    "    print(\"  accuracy\", prediction_evaluator.evaluate(results, {prediction_evaluator.metricName: \"accuracy\"}))\n",
    "    print(\"  f1score\", f1score)\n",
    "    print(\"---------\")\n",
    "    return f1score\n",
    "\n",
    "def model_selection_metrics(classifier_factory, train_set, validation_set):\n",
    "    num_folds = 3\n",
    "    f1scores = []\n",
    "    for i in range(10, 15):\n",
    "        seed = np.power(2, i)\n",
    "        print(\"with new seed:\")\n",
    "        multi_class_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "        param_grid = ParamGridBuilder().build()\n",
    "        cv = CrossValidator(estimator=classifier_factory(seed), evaluator=multi_class_evaluator, estimatorParamMaps=param_grid, numFolds=num_folds)\n",
    "        print(\"  training...\")\n",
    "        cv_model = cv.fit(train_set)\n",
    "        evaluate_and_get_f1score(\"training\", cv_model, train_set)\n",
    "        f1score = evaluate_and_get_f1score(\"validation\", cv_model, validation_set)\n",
    "        f1scores.append(f1score)\n",
    "    print(\"avg f1: \", np.mean(f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "\"page_view_about_avg\", \n",
    "\"page_view_error_avg\",\n",
    "\"page_view_next_song_avg\",\n",
    "\"page_view_roll_advert_avg\",\n",
    "\"page_view_thumbs_down_avg\",\n",
    "\"page_view_thumbs_up_avg\",\n",
    "\"page_view_add_friend_min\",\n",
    "\"page_view_add_to_playlist_min\",\n",
    "\"page_view_next_song_min\",\n",
    "\"page_view_roll_advert_min\",\n",
    "\"page_view_thumbs_down_min\",\n",
    "\"page_view_thumbs_up_min\",\n",
    "\"page_view_about_max\",\n",
    "\"page_view_add_friend_max\",\n",
    "\"page_view_add_to_playlist_max\",\n",
    "\"page_view_next_song_max\",\n",
    "\"page_view_roll_advert_max\",\n",
    "\"page_view_thumbs_down_max\",\n",
    "\"item_in_session_min\",\n",
    "\"item_in_session_max\",\n",
    "\"length_sum\",\n",
    "\"session_count_min\",\n",
    "\"active_time\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols = numeric_columns, outputCol = 'numeric_features')\n",
    "dataset = assembler.transform(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='numeric_features', outputCol='scaled_features', withStd=True)\n",
    "scale_model = scaler.fit(dataset)\n",
    "dataset = scale_model.transform(dataset)\n",
    "\n",
    "features_df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(churn=1, user_os=u'Windows-NT-5-1', page_view_about_avg=0.0, page_view_error_avg=0.14285714285714285, page_view_next_song_avg=48.666666666666664, page_view_roll_advert_avg=3.5238095238095237, page_view_thumbs_down_avg=1.5714285714285714, page_view_thumbs_up_avg=2.5238095238095237, page_view_add_friend_min=0, page_view_add_to_playlist_min=0, page_view_next_song_min=0, page_view_roll_advert_min=0, page_view_thumbs_down_min=0, page_view_thumbs_up_min=0, page_view_about_max=0, page_view_add_friend_max=3, page_view_add_to_playlist_max=4, page_view_next_song_max=170, page_view_roll_advert_max=11, page_view_thumbs_down_max=5, item_in_session_min=0, item_in_session_max=219, session_count_min=1, session_count_max=5, session_count_avg=3.142857142857143, location_state=u' OH', location_city=u'Findlay', length_sum=12.465937239422685, active_time=15.714485870664598, numeric_features=SparseVector(23, {1: 0.1429, 2: 48.6667, 3: 3.5238, 4: 1.5714, 5: 2.5238, 13: 3.0, 14: 4.0, 15: 170.0, 16: 11.0, 17: 5.0, 19: 219.0, 20: 12.4659, 21: 1.0, 22: 15.7145}), scaled_features=SparseVector(23, {1: 1.2606, 2: 1.5149, 3: 1.8074, 4: 2.8321, 5: 1.2592, 13: 0.9592, 14: 1.1007, 15: 1.7159, 16: 2.0796, 17: 2.5537, 19: 1.1667, 20: 8.8848, 21: 1.5713, 22: 28.1317}))]"
     ]
    }
   ],
   "source": [
    "features_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_dataset = features_df.select(col('scaled_features').alias('features'), \n",
    "                                   col('churn').alias('label')).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = churn_dataset.randomSplit([0.8, 0.2], seed=42)\n",
    "train = train.persist()\n",
    "test = test.persist()\n",
    "train, valid = train.randomSplit([0.8, 0.2], seed=42)\n",
    "train = train.persist()\n",
    "valid = valid.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Model parameters tuning on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "('  evaluation on ', 'training', '...')\n",
      "('  precision', 0.8283302473207421)\n",
      "('  recall', 0.8337907254943354)\n",
      "('  accuracy', 0.8337907254943354)\n",
      "('  f1score', 0.8080159153464045)\n",
      "---------\n",
      "('  evaluation on ', 'validation', '...')\n",
      "('  precision', 0.8354104701766067)\n",
      "('  recall', 0.8393109291160689)\n",
      "('  accuracy', 0.8393109291160689)\n",
      "('  f1score', 0.814618420175854)\n",
      "---------\n",
      "0.814618420175854"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "model = RandomForestClassifier()\n",
    "multi_class_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(model.maxDepth, [3, 5])\\\n",
    "    .addGrid(model.numTrees,[10, 15, 20, 25, 30])\\\n",
    "    .build()\n",
    "# param_grid = ParamGridBuilder().build()\n",
    "\n",
    "cv = CrossValidator(estimator=model, evaluator=multi_class_evaluator, estimatorParamMaps=param_grid, numFolds=num_folds)\n",
    "print(\"training...\")\n",
    "cv_model = cv.fit(train)\n",
    "evaluate_and_get_f1score(\"training\", cv_model, train)\n",
    "evaluate_and_get_f1score(\"validation\", cv_model, valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv_model.bestModel\n",
    "best_params = best_model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('subsamplingRate', ': ', 1.0)\n",
      "('predictionCol', ': ', 'prediction')\n",
      "('seed', ': ', -4140900678877021401)\n",
      "('rawPredictionCol', ': ', 'rawPrediction')\n",
      "('probabilityCol', ': ', 'probability')\n",
      "('featuresCol', ': ', 'features')\n",
      "('minInstancesPerNode', ': ', 1)\n",
      "('impurity', ': ', 'gini')\n",
      "('featureSubsetStrategy', ': ', 'auto')\n",
      "('cacheNodeIds', ': ', False)\n",
      "('maxDepth', ': ', 5)\n",
      "('maxMemoryInMB', ': ', 256)\n",
      "('numTrees', ': ', 20)\n",
      "('checkpointInterval', ': ', 10)\n",
      "('labelCol', ': ', 'label')\n",
      "('maxBins', ': ', 32)\n",
      "('minInfoGain', ': ', 0.0)"
     ]
    }
   ],
   "source": [
    "for param, value in best_params.items():\n",
    "    print(param.name, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('active_time', ': ', 0.5391434854428258)\n",
      "('session_count_min', ': ', 0.14610714929219407)\n",
      "('page_view_roll_advert_avg', ': ', 0.07360173499155157)\n",
      "('page_view_roll_advert_max', ': ', 0.05808957341877924)\n",
      "('page_view_thumbs_down_avg', ': ', 0.03183212491600829)\n",
      "('page_view_next_song_avg', ': ', 0.023661223550430585)\n",
      "('page_view_next_song_min', ': ', 0.022156787935501975)\n",
      "('length_sum', ': ', 0.01996390291604185)\n",
      "('page_view_roll_advert_min', ': ', 0.01714643793030387)\n",
      "('page_view_thumbs_down_max', ': ', 0.015245902287995583)\n",
      "('item_in_session_max', ': ', 0.014249017569289011)\n",
      "('page_view_next_song_max', ': ', 0.008496615290304469)\n",
      "('page_view_add_friend_min', ': ', 0.0058259861068556875)\n",
      "('page_view_add_to_playlist_max', ': ', 0.005020921193396526)\n",
      "('page_view_error_avg', ': ', 0.003927837496274965)\n",
      "('page_view_thumbs_up_avg', ': ', 0.0033456328016264756)\n",
      "('page_view_add_to_playlist_min', ': ', 0.00280802322233704)\n",
      "('page_view_add_friend_max', ': ', 0.0026040423091284975)\n",
      "('page_view_about_avg', ': ', 0.0022735748811093465)\n",
      "('page_view_thumbs_up_min', ': ', 0.0019001500574344966)\n",
      "('page_view_thumbs_down_min', ': ', 0.0015505445872445163)\n",
      "('page_view_about_max', ': ', 0.0006878293088061584)\n",
      "('item_in_session_min', ': ', 0.000361502494559831)"
     ]
    }
   ],
   "source": [
    "features_importance_list = list(zip(assembler.getInputCols(), best_model.featureImportances.values))\n",
    "features_importance_list = sorted(features_importance_list, key=lambda pair: pair[1])\n",
    "features_importance_list.reverse()\n",
    "for feature, importance in features_importance_list:\n",
    "    print(feature, \": \", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Evaluation on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('  evaluation on ', 'test', '...')\n",
      "('  precision', 0.8282483758049413)\n",
      "('  recall', 0.8355525965379494)\n",
      "('  accuracy', 0.8355525965379494)\n",
      "('  f1score', 0.8124129861525997)\n",
      "---------\n",
      "0.8124129861525997"
     ]
    }
   ],
   "source": [
    "evaluate_and_get_f1score(\"test\", best_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
